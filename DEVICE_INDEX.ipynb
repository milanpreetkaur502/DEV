{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "11f4a074",
   "metadata": {},
   "outputs": [
    {
     "ename": "error",
     "evalue": "OpenCV(4.5.3) C:\\Users\\runneradmin\\AppData\\Local\\Temp\\pip-req-build-sn_xpupm\\opencv\\modules\\imgproc\\src\\color.cpp:182: error: (-215:Assertion failed) !_src.empty() in function 'cv::cvtColor'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31merror\u001b[0m                                     Traceback (most recent call last)",
      "\u001b[1;32mC:\\Users\\NILOHI~1\\AppData\\Local\\Temp/ipykernel_25400/2737702868.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     23\u001b[0m     \u001b[0mdiff1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mabsdiff\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mframe11\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mframe12\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;31m#Absoulte difference between the pixels of the  1st and 2nd image frame or By using this we will be able to extract just the pixels of the objects that are moving\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     24\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 25\u001b[1;33m     \u001b[0mgray1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcvtColor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdiff1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mCOLOR_BGR2GRAY\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;31m# converting this difference into gray scale mode and  grayscale images are single-dimensional, Reduces model complexity\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     26\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     27\u001b[0m     \u001b[0mblur1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mGaussianBlur\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgray1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m5\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;31m#Gaussian filter is a low-pass filter that removes the high-frequency components.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31merror\u001b[0m: OpenCV(4.5.3) C:\\Users\\runneradmin\\AppData\\Local\\Temp\\pip-req-build-sn_xpupm\\opencv\\modules\\imgproc\\src\\color.cpp:182: error: (-215:Assertion failed) !_src.empty() in function 'cv::cvtColor'\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "import cv2\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "import time\n",
    "import random\n",
    "DEVICE_INDEX =  \"DEFAULT_CAMERA_NAME= '/dev/v4l/by-id/usb-e-con_systems_See3CAM_130_3B128E0B-video-index0'\n",
    "                device_num = 0\n",
    "                if os.path.exists(DEFAULT_CAMERA_NAME):\n",
    "                    device_path = os.aoth.realpath(DEFAULT_CAMERA_NAME)\n",
    "                    device_re = re.compile(\"\\dev/\\video(\\d+)\")\n",
    "                    info = device_re.match(device_path)\n",
    "                    if info:\n",
    "                        device_num = int(info.group(1))\n",
    "                        print(\"Using default video capture device on /dev/video\" + str(device_num))\n",
    "                cap=cv2.VideoCapture(device_num)\"\n",
    "                 \n",
    "\n",
    "\n",
    "cap=cv2. VideoCapture(f\"v4l2src device={DEVICE_INDEX} ! video/x-raw, width=640, height=480, format=(string)UYVY, framerate=60/1 ! decodebin ! videoconvert ! appsink\",cv2.CAP_GSTREAMER)\n",
    "    \n",
    "\n",
    "aTQ1\n",
    "        \n",
    "\n",
    "\n",
    "def rescale_frame(frame, percent=71): #Setting parameters\n",
    "    width = int(frame.shape[1] * percent / 100)\n",
    "    height = int(frame.shape[0] * percent / 100)\n",
    "    dim = (width, height)\n",
    "    return cv2.resize(frame, dim, interpolation=cv2.INTER_AREA)\n",
    "\n",
    "while (True):\n",
    "    ret1, frame11 = cap.read()\n",
    "    ret1, frame12 = cap.read()\n",
    "\n",
    "    diff1 = cv2.absdiff(frame11, frame12)#Absoulte difference between the pixels of the  1st and 2nd image frame or By using this we will be able to extract just the pixels of the objects that are moving\n",
    "\n",
    "    gray1 = cv2.cvtColor(diff1, cv2.COLOR_BGR2GRAY)# converting this difference into gray scale mode and  grayscale images are single-dimensional, Reduces model complexity\n",
    "\n",
    "    blur1 = cv2.GaussianBlur(gray1, (5, 5), 0)#Gaussian filter is a low-pass filter that removes the high-frequency components.\n",
    "\n",
    "    _, tresh1 = cv2.threshold(blur1, 40, 255, cv2.THRESH_BINARY)# way to extract useful information encoded into pixels while minimizing background noise or upto which we want motion to be detected\n",
    "\n",
    "    dilated1 = cv2.dilate(tresh1, None, iterations=3)#iterations means how accurate our smoothening will be if we inc background noise aajegi.\n",
    "\n",
    "    contours1, _ = cv2.findContours(dilated1, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE) # points at which motion is happening.\n",
    "\n",
    "    for contour in contours1:\n",
    "        (x, y, w, h) = cv2.boundingRect(contour)# making of rectangular frame.\n",
    "        if cv2.contourArea(contour) < 2000: # if area of contour is less than 2000, then we are going to do nothing.But if its greater than 2000, a rectangle will be drawn.\n",
    "            continue\n",
    "        cv2.rectangle(frame11, (x, y), (x + w, y + h), (0, 255, 0), 2)\n",
    "        cv2.putText(frame11, \"Status: {}\".format('Insect captured'), (10, 20), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 255), 3)\n",
    "        t = time.localtime()\n",
    "        path = 'E:/capture/' # path were images will be stored\n",
    "        num = random.random()\n",
    "        filename = path + str(t[0]) + str(t[1]) + str(t[2]) + \"_\" + str(t[3]) + str(t[4]) + str(t[5]) + str(num) + \".jpg\"\n",
    "        cv2.imwrite(filename, frame11, [int(cv2.IMWRITE_JPEG_QUALITY), 95])\n",
    "        print('Image being capture...', filename)\n",
    "\n",
    "    # cv2.line(frame, (0, 300), (200, 200), (0, 255, 0), 5)\n",
    "    resizedframe11 = rescale_frame(frame11, percent=75)\n",
    "    cv2.imshow('Ready to capture', resizedframe11)\n",
    "\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "677c6f7a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
